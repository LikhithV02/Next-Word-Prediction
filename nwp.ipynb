{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ti00nymvC11i"},"outputs":[],"source":["import numpy as np\n","from nltk.tokenize import RegexpTokenizer\n","from keras.models import Sequential, load_model\n","from keras.layers import LSTM\n","from keras.layers.core import Dense, Activation\n","from keras.optimizers import RMSprop\n","import matplotlib.pyplot as plt\n","import pickle\n","import heapq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAkjDDINC11j","outputId":"5b1d6c38-f9de-4c48-d964-22bf40d9eb20"},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus length: 581533\n"]}],"source":["text = open('1661-0.txt', encoding='utf8').read().lower()\n","print('corpus length:', len(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDCUCXvLC11l"},"outputs":[],"source":["tokenizer = RegexpTokenizer(r'\\w+')\n","words = tokenizer.tokenize(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4wGcqvkMC11l"},"outputs":[],"source":["unique_words = np.unique(words)\n","unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGc1oMabC11l"},"outputs":[],"source":["WORD_LENGTH = 5\n","prev_words = []\n","next_words = []\n","for i in range(len(words) - WORD_LENGTH):\n","    prev_words.append(words[i:i + WORD_LENGTH])\n","    next_words.append(words[i + WORD_LENGTH])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UX4TqEBC11m"},"outputs":[],"source":["X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n","Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hb2ywdrbC11m"},"outputs":[],"source":["for i, each_words in enumerate(prev_words):\n","    for j, each_word in enumerate(each_words):\n","        X[i, j, unique_word_index[each_word]] = 1\n","    Y[i, unique_word_index[next_words[i]]] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2Ccgf6vC11m","outputId":"e0bbd0f5-2237-4886-af51-f432d6a122dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 128)               4256768   \n","                                                                 \n"," dense (Dense)               (None, 8185)              1055865   \n","                                                                 \n"," activation (Activation)     (None, 8185)              0         \n","                                                                 \n","=================================================================\n","Total params: 5,312,633\n","Trainable params: 5,312,633\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n","model.add(Dense(len(unique_words)))\n","#model.add(Dense(len(unique_words)/2))\n","model.add(Activation('softmax'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahVNnIfmC11n","outputId":"78d9fe14-26e9-444d-cfb2-267c16eaf521"},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"]}],"source":["from tensorflow import keras\n","from keras.utils.vis_utils import plot_model\n","\n","keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)  # type: ignore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PObAiMTBC11n","outputId":"0db23ac2-ac83-4101-f8ba-ea85830bdd35"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","845/845 [==============================] - 190s 221ms/step - loss: 6.1074 - accuracy: 0.1151 - val_loss: 8.2134 - val_accuracy: 0.1218\n","Epoch 2/100\n","845/845 [==============================] - 163s 193ms/step - loss: 5.9055 - accuracy: 0.1558 - val_loss: 8.0750 - val_accuracy: 0.1273\n","Epoch 3/100\n","845/845 [==============================] - 155s 184ms/step - loss: 5.4202 - accuracy: 0.1931 - val_loss: 8.4537 - val_accuracy: 0.1181\n","Epoch 4/100\n","845/845 [==============================] - 174s 206ms/step - loss: 4.8675 - accuracy: 0.2402 - val_loss: 9.5028 - val_accuracy: 0.1319\n","Epoch 5/100\n","845/845 [==============================] - 185s 219ms/step - loss: 4.2908 - accuracy: 0.2927 - val_loss: 10.3577 - val_accuracy: 0.1227\n","Epoch 6/100\n","845/845 [==============================] - 173s 204ms/step - loss: 3.7253 - accuracy: 0.3524 - val_loss: 10.7306 - val_accuracy: 0.1245\n","Epoch 7/100\n","845/845 [==============================] - 190s 224ms/step - loss: 3.2215 - accuracy: 0.4109 - val_loss: 11.4451 - val_accuracy: 0.1181\n","Epoch 8/100\n","845/845 [==============================] - 174s 205ms/step - loss: 2.7996 - accuracy: 0.4625 - val_loss: 12.1252 - val_accuracy: 0.1099\n","Epoch 9/100\n","845/845 [==============================] - 171s 202ms/step - loss: 2.4497 - accuracy: 0.5102 - val_loss: 12.5664 - val_accuracy: 0.1264\n","Epoch 10/100\n","845/845 [==============================] - 168s 199ms/step - loss: 2.1753 - accuracy: 0.5523 - val_loss: 13.3070 - val_accuracy: 0.1209\n","Epoch 11/100\n","845/845 [==============================] - 175s 207ms/step - loss: 1.9609 - accuracy: 0.5851 - val_loss: 13.6224 - val_accuracy: 0.0998\n","Epoch 12/100\n","845/845 [==============================] - 168s 199ms/step - loss: 1.7811 - accuracy: 0.6133 - val_loss: 13.8734 - val_accuracy: 0.1081\n","Epoch 13/100\n","845/845 [==============================] - 162s 192ms/step - loss: 1.6336 - accuracy: 0.6392 - val_loss: 14.3786 - val_accuracy: 0.1035\n","Epoch 14/100\n","845/845 [==============================] - 157s 186ms/step - loss: 1.5156 - accuracy: 0.6591 - val_loss: 14.4042 - val_accuracy: 0.1126\n","Epoch 15/100\n","845/845 [==============================] - 163s 193ms/step - loss: 1.3972 - accuracy: 0.6817 - val_loss: 15.1123 - val_accuracy: 0.1062\n","Epoch 16/100\n","845/845 [==============================] - 165s 195ms/step - loss: 1.3181 - accuracy: 0.6961 - val_loss: 15.1479 - val_accuracy: 0.0943\n","Epoch 17/100\n","845/845 [==============================] - 155s 183ms/step - loss: 1.2395 - accuracy: 0.7122 - val_loss: 15.3163 - val_accuracy: 0.0998\n","Epoch 18/100\n","845/845 [==============================] - 149s 176ms/step - loss: 1.1687 - accuracy: 0.7236 - val_loss: 15.3374 - val_accuracy: 0.0925\n","Epoch 19/100\n","845/845 [==============================] - 153s 181ms/step - loss: 1.1076 - accuracy: 0.7353 - val_loss: 15.7484 - val_accuracy: 0.0980\n","Epoch 20/100\n","845/845 [==============================] - 143s 169ms/step - loss: 1.0572 - accuracy: 0.7449 - val_loss: 16.1116 - val_accuracy: 0.0934\n","Epoch 21/100\n","845/845 [==============================] - 151s 179ms/step - loss: 1.0076 - accuracy: 0.7555 - val_loss: 16.4056 - val_accuracy: 0.0842\n","Epoch 22/100\n","845/845 [==============================] - 150s 177ms/step - loss: 0.9704 - accuracy: 0.7624 - val_loss: 16.5473 - val_accuracy: 0.0897\n","Epoch 23/100\n","845/845 [==============================] - 150s 177ms/step - loss: 0.9360 - accuracy: 0.7696 - val_loss: 16.9435 - val_accuracy: 0.0861\n","Epoch 24/100\n","845/845 [==============================] - 153s 181ms/step - loss: 0.9102 - accuracy: 0.7737 - val_loss: 16.9275 - val_accuracy: 0.0879\n","Epoch 25/100\n","845/845 [==============================] - 155s 184ms/step - loss: 0.8739 - accuracy: 0.7824 - val_loss: 17.1693 - val_accuracy: 0.0778\n","Epoch 26/100\n","845/845 [==============================] - 153s 181ms/step - loss: 0.8504 - accuracy: 0.7872 - val_loss: 17.1239 - val_accuracy: 0.0916\n","Epoch 27/100\n","845/845 [==============================] - 157s 186ms/step - loss: 0.8241 - accuracy: 0.7924 - val_loss: 17.2831 - val_accuracy: 0.0751\n","Epoch 28/100\n","845/845 [==============================] - 151s 179ms/step - loss: 0.8067 - accuracy: 0.7969 - val_loss: 17.3618 - val_accuracy: 0.0797\n","Epoch 29/100\n","845/845 [==============================] - 157s 186ms/step - loss: 0.7828 - accuracy: 0.8017 - val_loss: 17.5027 - val_accuracy: 0.0879\n","Epoch 30/100\n","845/845 [==============================] - 154s 182ms/step - loss: 0.7615 - accuracy: 0.8072 - val_loss: 17.8033 - val_accuracy: 0.0842\n","Epoch 31/100\n","845/845 [==============================] - 149s 177ms/step - loss: 0.7511 - accuracy: 0.8078 - val_loss: 17.9170 - val_accuracy: 0.0833\n","Epoch 32/100\n","845/845 [==============================] - 152s 180ms/step - loss: 0.7348 - accuracy: 0.8123 - val_loss: 18.0065 - val_accuracy: 0.0879\n","Epoch 33/100\n","845/845 [==============================] - 210s 249ms/step - loss: 0.7181 - accuracy: 0.8161 - val_loss: 18.0845 - val_accuracy: 0.0797\n","Epoch 34/100\n","845/845 [==============================] - 214s 253ms/step - loss: 0.7076 - accuracy: 0.8192 - val_loss: 18.3192 - val_accuracy: 0.0760\n","Epoch 35/100\n","845/845 [==============================] - 239s 283ms/step - loss: 0.6887 - accuracy: 0.8229 - val_loss: 18.4960 - val_accuracy: 0.0824\n","Epoch 36/100\n","845/845 [==============================] - 210s 249ms/step - loss: 0.6708 - accuracy: 0.8259 - val_loss: 18.6221 - val_accuracy: 0.0778\n","Epoch 37/100\n","845/845 [==============================] - 198s 234ms/step - loss: 0.6629 - accuracy: 0.8293 - val_loss: 18.5425 - val_accuracy: 0.0925\n","Epoch 38/100\n","845/845 [==============================] - 183s 217ms/step - loss: 0.6577 - accuracy: 0.8316 - val_loss: 18.5981 - val_accuracy: 0.0879\n","Epoch 39/100\n","845/845 [==============================] - 183s 217ms/step - loss: 0.6461 - accuracy: 0.8332 - val_loss: 18.7041 - val_accuracy: 0.0842\n","Epoch 40/100\n","845/845 [==============================] - 180s 214ms/step - loss: 0.6415 - accuracy: 0.8341 - val_loss: 18.6506 - val_accuracy: 0.0815\n","Epoch 41/100\n","845/845 [==============================] - 172s 204ms/step - loss: 0.6256 - accuracy: 0.8368 - val_loss: 18.9703 - val_accuracy: 0.0842\n","Epoch 42/100\n","845/845 [==============================] - 180s 213ms/step - loss: 0.6146 - accuracy: 0.8394 - val_loss: 19.0261 - val_accuracy: 0.0852\n","Epoch 43/100\n","845/845 [==============================] - 171s 203ms/step - loss: 0.6077 - accuracy: 0.8414 - val_loss: 19.0279 - val_accuracy: 0.0833\n","Epoch 44/100\n","845/845 [==============================] - 186s 221ms/step - loss: 0.6037 - accuracy: 0.8410 - val_loss: 19.0417 - val_accuracy: 0.0916\n","Epoch 45/100\n","845/845 [==============================] - 183s 216ms/step - loss: 0.5965 - accuracy: 0.8440 - val_loss: 19.2157 - val_accuracy: 0.0879\n","Epoch 46/100\n","845/845 [==============================] - 210s 248ms/step - loss: 0.5841 - accuracy: 0.8475 - val_loss: 19.4331 - val_accuracy: 0.0907\n","Epoch 47/100\n","845/845 [==============================] - 188s 223ms/step - loss: 0.5684 - accuracy: 0.8510 - val_loss: 19.5353 - val_accuracy: 0.0861\n","Epoch 48/100\n","845/845 [==============================] - 173s 205ms/step - loss: 0.5704 - accuracy: 0.8503 - val_loss: 19.5806 - val_accuracy: 0.0879\n","Epoch 49/100\n","845/845 [==============================] - 161s 191ms/step - loss: 0.5660 - accuracy: 0.8515 - val_loss: 19.9008 - val_accuracy: 0.0797\n","Epoch 50/100\n","845/845 [==============================] - 152s 180ms/step - loss: 0.5595 - accuracy: 0.8526 - val_loss: 19.8669 - val_accuracy: 0.0824\n","Epoch 51/100\n","845/845 [==============================] - 152s 179ms/step - loss: 0.5488 - accuracy: 0.8556 - val_loss: 19.9065 - val_accuracy: 0.0815\n","Epoch 52/100\n","845/845 [==============================] - 144s 170ms/step - loss: 0.5400 - accuracy: 0.8570 - val_loss: 19.9012 - val_accuracy: 0.0815\n","Epoch 53/100\n","845/845 [==============================] - 143s 169ms/step - loss: 0.5361 - accuracy: 0.8580 - val_loss: 19.8614 - val_accuracy: 0.0833\n","Epoch 54/100\n","845/845 [==============================] - 139s 164ms/step - loss: 0.5294 - accuracy: 0.8594 - val_loss: 19.9726 - val_accuracy: 0.0797\n","Epoch 55/100\n","845/845 [==============================] - 143s 169ms/step - loss: 0.5268 - accuracy: 0.8600 - val_loss: 19.9716 - val_accuracy: 0.0897\n","Epoch 56/100\n","845/845 [==============================] - 158s 186ms/step - loss: 0.5177 - accuracy: 0.8622 - val_loss: 20.2521 - val_accuracy: 0.0870\n","Epoch 57/100\n","845/845 [==============================] - 144s 171ms/step - loss: 0.5145 - accuracy: 0.8629 - val_loss: 20.1610 - val_accuracy: 0.0852\n","Epoch 58/100\n","845/845 [==============================] - 155s 184ms/step - loss: 0.5157 - accuracy: 0.8628 - val_loss: 20.4104 - val_accuracy: 0.0806\n","Epoch 59/100\n","845/845 [==============================] - 145s 172ms/step - loss: 0.5082 - accuracy: 0.8655 - val_loss: 20.6129 - val_accuracy: 0.0742\n","Epoch 60/100\n","845/845 [==============================] - 149s 176ms/step - loss: 0.5014 - accuracy: 0.8663 - val_loss: 20.8900 - val_accuracy: 0.0678\n","Epoch 61/100\n","845/845 [==============================] - 258s 306ms/step - loss: 0.5017 - accuracy: 0.8673 - val_loss: 20.6553 - val_accuracy: 0.0742\n","Epoch 62/100\n","845/845 [==============================] - 157s 185ms/step - loss: 0.5001 - accuracy: 0.8665 - val_loss: 20.5518 - val_accuracy: 0.0797\n","Epoch 63/100\n","845/845 [==============================] - 157s 186ms/step - loss: 0.4963 - accuracy: 0.8687 - val_loss: 20.9569 - val_accuracy: 0.0742\n","Epoch 64/100\n","845/845 [==============================] - 165s 195ms/step - loss: 0.4930 - accuracy: 0.8688 - val_loss: 20.8545 - val_accuracy: 0.0861\n","Epoch 65/100\n","845/845 [==============================] - 154s 183ms/step - loss: 0.4896 - accuracy: 0.8695 - val_loss: 21.2168 - val_accuracy: 0.0760\n","Epoch 66/100\n","845/845 [==============================] - 163s 193ms/step - loss: 0.4873 - accuracy: 0.8706 - val_loss: 20.9776 - val_accuracy: 0.0824\n","Epoch 67/100\n","845/845 [==============================] - 178s 211ms/step - loss: 0.4799 - accuracy: 0.8723 - val_loss: 21.0402 - val_accuracy: 0.0797\n","Epoch 68/100\n","845/845 [==============================] - 179s 212ms/step - loss: 0.4653 - accuracy: 0.8761 - val_loss: 21.3418 - val_accuracy: 0.0824\n","Epoch 69/100\n","845/845 [==============================] - 190s 225ms/step - loss: 0.4703 - accuracy: 0.8744 - val_loss: 21.2009 - val_accuracy: 0.0842\n","Epoch 70/100\n","845/845 [==============================] - 152s 180ms/step - loss: 0.4601 - accuracy: 0.8768 - val_loss: 21.2511 - val_accuracy: 0.0778\n","Epoch 71/100\n","845/845 [==============================] - 159s 188ms/step - loss: 0.4648 - accuracy: 0.8756 - val_loss: 21.3485 - val_accuracy: 0.0806\n","Epoch 72/100\n","845/845 [==============================] - 156s 185ms/step - loss: 0.4581 - accuracy: 0.8781 - val_loss: 21.6970 - val_accuracy: 0.0751\n","Epoch 73/100\n","845/845 [==============================] - 146s 173ms/step - loss: 0.4609 - accuracy: 0.8770 - val_loss: 21.5308 - val_accuracy: 0.0733\n","Epoch 74/100\n","845/845 [==============================] - 154s 182ms/step - loss: 0.4517 - accuracy: 0.8788 - val_loss: 21.7293 - val_accuracy: 0.0733\n","Epoch 75/100\n","845/845 [==============================] - 180s 213ms/step - loss: 0.4461 - accuracy: 0.8789 - val_loss: 21.6702 - val_accuracy: 0.0742\n","Epoch 76/100\n","845/845 [==============================] - 185s 219ms/step - loss: 0.4462 - accuracy: 0.8804 - val_loss: 21.5514 - val_accuracy: 0.0714\n","Epoch 77/100\n","845/845 [==============================] - 6329s 7s/step - loss: 0.4431 - accuracy: 0.8808 - val_loss: 21.8543 - val_accuracy: 0.0769\n","Epoch 78/100\n","845/845 [==============================] - 172s 204ms/step - loss: 0.4443 - accuracy: 0.8803 - val_loss: 21.9329 - val_accuracy: 0.0733\n","Epoch 79/100\n","845/845 [==============================] - 165s 195ms/step - loss: 0.4340 - accuracy: 0.8837 - val_loss: 21.7285 - val_accuracy: 0.0742\n","Epoch 80/100\n","845/845 [==============================] - 343s 407ms/step - loss: 0.4330 - accuracy: 0.8842 - val_loss: 22.0944 - val_accuracy: 0.0668\n","Epoch 81/100\n","845/845 [==============================] - 179s 212ms/step - loss: 0.4340 - accuracy: 0.8839 - val_loss: 21.9036 - val_accuracy: 0.0696\n","Epoch 82/100\n","845/845 [==============================] - 182s 216ms/step - loss: 0.4346 - accuracy: 0.8831 - val_loss: 21.9978 - val_accuracy: 0.0760\n","Epoch 83/100\n","845/845 [==============================] - 182s 216ms/step - loss: 0.4315 - accuracy: 0.8853 - val_loss: 22.1141 - val_accuracy: 0.0668\n","Epoch 84/100\n","845/845 [==============================] - 165s 196ms/step - loss: 0.4266 - accuracy: 0.8859 - val_loss: 22.1732 - val_accuracy: 0.0742\n","Epoch 85/100\n","845/845 [==============================] - 166s 196ms/step - loss: 0.4287 - accuracy: 0.8842 - val_loss: 22.4271 - val_accuracy: 0.0788\n","Epoch 86/100\n","845/845 [==============================] - 567s 671ms/step - loss: 0.4282 - accuracy: 0.8857 - val_loss: 22.4581 - val_accuracy: 0.0760\n","Epoch 87/100\n","845/845 [==============================] - 180s 213ms/step - loss: 0.4292 - accuracy: 0.8853 - val_loss: 22.5477 - val_accuracy: 0.0705\n","Epoch 88/100\n","845/845 [==============================] - 177s 209ms/step - loss: 0.4180 - accuracy: 0.8874 - val_loss: 22.3804 - val_accuracy: 0.0778\n","Epoch 89/100\n","845/845 [==============================] - 176s 208ms/step - loss: 0.4174 - accuracy: 0.8894 - val_loss: 22.6054 - val_accuracy: 0.0815\n","Epoch 90/100\n","845/845 [==============================] - 160s 190ms/step - loss: 0.4164 - accuracy: 0.8890 - val_loss: 22.5222 - val_accuracy: 0.0778\n","Epoch 91/100\n","845/845 [==============================] - 149s 177ms/step - loss: 0.4175 - accuracy: 0.8890 - val_loss: 22.7356 - val_accuracy: 0.0751\n","Epoch 92/100\n","845/845 [==============================] - 158s 186ms/step - loss: 0.4152 - accuracy: 0.8893 - val_loss: 22.8341 - val_accuracy: 0.0788\n","Epoch 93/100\n","845/845 [==============================] - 138s 164ms/step - loss: 0.4128 - accuracy: 0.8898 - val_loss: 23.0151 - val_accuracy: 0.0769\n","Epoch 94/100\n","845/845 [==============================] - 177s 209ms/step - loss: 0.4104 - accuracy: 0.8915 - val_loss: 22.8997 - val_accuracy: 0.0733\n","Epoch 95/100\n","845/845 [==============================] - 174s 205ms/step - loss: 0.4157 - accuracy: 0.8894 - val_loss: 22.8945 - val_accuracy: 0.0797\n","Epoch 96/100\n","845/845 [==============================] - 183s 217ms/step - loss: 0.4073 - accuracy: 0.8914 - val_loss: 23.0764 - val_accuracy: 0.0797\n","Epoch 97/100\n","845/845 [==============================] - 182s 215ms/step - loss: 0.4026 - accuracy: 0.8928 - val_loss: 23.1705 - val_accuracy: 0.0723\n","Epoch 98/100\n","845/845 [==============================] - 186s 220ms/step - loss: 0.3999 - accuracy: 0.8933 - val_loss: 22.9685 - val_accuracy: 0.0797\n","Epoch 99/100\n","845/845 [==============================] - 191s 226ms/step - loss: 0.4034 - accuracy: 0.8915 - val_loss: 22.9399 - val_accuracy: 0.0797\n","Epoch 100/100\n","845/845 [==============================] - 183s 217ms/step - loss: 0.4040 - accuracy: 0.8922 - val_loss: 23.0327 - val_accuracy: 0.0842\n"]}],"source":["model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.02), metrics=['accuracy'])\n","history = model.fit(X, Y, validation_split=0.2, batch_size=128, epochs=100, shuffle=True).history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7c_OSrtpC11o"},"outputs":[],"source":["model.save('nwp.h5')\n","pickle.dump(history, open(\"history.p\", \"wb\"))\n","\n","model = load_model('nwp.h5')\n","history = pickle.load(open(\"history.p\", \"rb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAMBAEcfC11o"},"outputs":[],"source":["def prepare_input(text):\n","    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n","    for t, word in enumerate(text.split()):\n","        print(word)\n","        x[0, t, unique_word_index[word]] = 1\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAIMY95UC11p"},"outputs":[],"source":["def sample(preds, top_n=3):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds)\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    return heapq.nlargest(top_n, range(len(preds)), preds.take)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVjb3_EiC11p"},"outputs":[],"source":["def predict_completions(text, n=3):\n","    if text == \"\":\n","        return(\"0\")\n","    x = prepare_input(text)\n","    preds = model.predict(x, verbose=0)[0]  # type: ignore\n","    next_indices = sample(preds, n)\n","    return [unique_words[idx] for idx in next_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoB1U5D8C11p","outputId":"0a1a8fbf-c261-4e67-fbef-344d6892059c"},"outputs":[{"name":"stdout","output_type":"stream","text":["correct sentence:  Your life will never be there in the same situation again\n","Sequence:  your life will never be\n","your\n","life\n","will\n","never\n","be\n","next possible words:  ['upon', 'carried', 'shoulders']\n"]}],"source":["q = \"Your life will never be there in the same situation again\"\n","print(\"correct sentence: \",q)\n","seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n","print(\"Sequence: \",seq)\n","print(\"next possible words: \", predict_completions(seq, 3))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ba77dbe0515d95964a24acb088a21d437db84836d84abb35f105870d8fde31dd"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}